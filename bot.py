import logging
import re
import sys
import threading
import time
import traceback
from contextlib import suppress
from pathlib import Path
from threading import Lock
from typing import Callable

from storage import (
    init_db,
    clear_history,
    iter_history_chat_ids,
    load_history,
    save_history,
    r,
    TTL,
)
from telebot import types

# Ensure media handlers are registered
import media
from media import multimedia_menu

# Register web search handlers (command /web)
import handlers.web  # noqa: F401 - —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Ö–µ–Ω–¥–ª–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ –∏–º–ø–æ—Ä—Ç

from internet import ask_gpt_web, should_escalate_to_web, should_prefer_web

from bot_utils import show_typing

# --- –ö–æ–Ω—Ñ–∏–≥: –∑–Ω–∞—á–µ–Ω–∏—è —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω—ã –≤ settings.py ---
from settings import (
    bot,
    client,
    CHAT_MODEL,
    HISTORY_LIMIT,
    is_owner,
    SYSTEM_PROMPT,
)
from openai_adapter import (
    coerce_content_to_text,
    extract_response_text,
    prepare_responses_input,
)
from text_utils import sanitize_for_telegram, sanitize_model_output

# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥—ã /post
import auto_post  # noqa: F401 - —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥—ã /post

# Initialize the SQLite storage before handling any requests
init_db()

# --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –∑–∞–ø–∏—Å—å—é –≤ —Ñ–∞–π–ª ---
LOG_FILE = Path(__file__).resolve().parent / "gpsbot.log"

logging.basicConfig(
    filename=str(LOG_FILE),
    level=logging.ERROR,
    format="%(asctime)s [%(levelname)s] %(message)s",
)


def log_exception(exc: Exception) -> None:
    """Log unexpected polling exceptions both to stdout and a file."""
    tb = traceback.format_exc()
    msg = f"CRITICAL: polling crashed: {exc}\n{tb}"
    print(msg)
    logging.error(msg)
    sys.stdout.flush()


def replace_foreign_links_with_ru(text: str) -> str:
    """–ó–∞–º–µ–Ω—è–µ—Ç –∑–∞—Ä—É–±–µ–∂–Ω—ã–µ —Å—Å—ã–ª–∫–∏ (weather.com, wikipedia.org –∏ —Ç.–¥.) –Ω–∞ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∞–Ω–∞–ª–æ–≥–∏."""
    replacements = {
        r"https?://(www\.)?weather\.com[^\s)]*": "https://yandex.ru/pogoda",
        r"https?://(en\.)?wikipedia\.org[^\s)]*": "https://ru.wikipedia.org",
        r"https?://(www\.)?cnn\.com[^\s)]*": "https://ria.ru",
        r"https?://(www\.)?bbc\.com[^\s)]*": "https://tass.ru",
        r"https?://(www\.)?google\.com[^\s)]*": "https://yandex.ru",
    }
    for pattern, replacement in replacements.items():
        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
    return text


# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ø–æ–¥–ø–∏—Å–∫–∏ ---
CHANNEL_USERNAME = "@SynteraAI"
BOT_DEEP_LINK = "https://t.me/SynteraGPT_bot"
PHOTO_FILE = Path(__file__).resolve().parent / "baner_dlya_perehoda.png"
START_CAPTION = (
    "<b>SynteraGPT</b>\n\n"
    "–ß–∞—Ç-–±–æ—Ç —Å –≤—ã—Ö–æ–¥–æ–º –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç: –Ω–∞–π–¥—ë—Ç, –ø—Ä–æ–≤–µ—Ä–∏—Ç –∏ –æ–±—ä—è—Å–Ω–∏—Ç.\n\n"
    "–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\n"
    "‚Äî –ü–æ–∏—Å–∫ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–∫—Ç–æ–≤ –æ–Ω–ª–∞–π–Ω\n"
    "‚Äî GPT-5 –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ 24/7\n"
    "‚Äî –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n"
    "‚Äî –ö–æ—Ä–æ—Ç–∫–∏–µ –∏ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–µ –æ—Ç–≤–µ—Ç—ã\n\n"
    "üî• –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º ‚Äî –ø–æ–ø—Ä–æ–±—É–π –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã –∏ –æ—Ü–µ–Ω–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏.\n\n"
    "–ü—Ä–∏—Å–æ–µ–¥–∏–Ω—è–π—Å—è –∫ –∫–∞–Ω–∞–ª—É @SynteraAI, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è."
)

# --- –•—Ä–∞–Ω–∏–ª–∏—â–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π ---
# –•—Ä–∞–Ω–∏–ª–∏—â–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–ª–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à)
user_histories = {}  # {chat_id: [ {role: "user"/"assistant", content: "..."}, ... ]}
user_messages = {}  # {chat_id: [message_id, ...]}

# –∫–µ—à –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ (–¥–ª—è –æ—Ñ–ª–∞–π–Ω-—Ä–µ–∂–∏–º–∞, –µ—Å–ª–∏ Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)
_language_cache: dict[int, str] = {}

# --- –ö—ç—à –æ—Ç–≤–µ—Ç–æ–≤ ---
# –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ—Ç–≤–µ—Ç—ã: –∫–ª—é—á (chat_id, text_lower) -> –æ—Ç–≤–µ—Ç.
response_cache: dict[tuple[int, str], str] = {}


def _ensure_history_cached(chat_id: int) -> None:
    if chat_id not in user_histories:
        past = load_history(chat_id)
        if past:
            user_histories[chat_id] = past
        else:
            user_histories[chat_id] = []


def send_start_window(chat_id) -> None:
    kb = types.InlineKeyboardMarkup()
    kb.add(types.InlineKeyboardButton("–û—Ç–∫—Ä—ã—Ç—å –±–æ—Ç–∞", url=BOT_DEEP_LINK))

    try:
        with PHOTO_FILE.open("rb") as photo:
            bot.send_photo(
                chat_id,
                photo,
                caption=START_CAPTION,
                reply_markup=kb,
                parse_mode="HTML",
            )
    except FileNotFoundError:
        bot.send_message(
            chat_id,
            START_CAPTION,
            reply_markup=kb,
            parse_mode="HTML",
        )


# --- /media
@bot.message_handler(commands=["media"])
def cmd_media(m):
    bot.send_message(
        m.chat.id,
        "–î–æ—Å—Ç—É–ø–Ω—ã–µ –º—É–ª—å—Ç–∏–º–µ–¥–∏–∞ —Ñ—É–Ω–∫—Ü–∏–∏:",
        reply_markup=multimedia_menu(),
    )


# --- /profile
@bot.message_handler(commands=["profile"])
def cmd_profile(m):
    bot.send_message(
        m.chat.id,
        f"–í–∞—à ID: {m.from_user.id}\n"
        f"–ò–º—è: {m.from_user.first_name}\n"
        "–ü–æ–¥–ø–∏—Å–∫–∞: FREE (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)",
    )


def send_and_store(chat_id, text, **kwargs):
    msg = bot.send_message(chat_id, text, **kwargs)
    user_messages.setdefault(chat_id, []).append(msg.message_id)
    return msg

# --- –û–±—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è ---


def send_welcome_menu(chat_id: int) -> None:
    send_and_store(
        chat_id,
        START_CAPTION,
        reply_markup=main_menu(),
        parse_mode="HTML",
    )

# --- –ö–ª–∞–≤–∏–∞—Ç—É—Ä—ã ---

def main_menu():
    kb = types.ReplyKeyboardMarkup(resize_keyboard=True, row_width=2)
    kb.add(
        types.KeyboardButton("–ú–µ–¥–∏–∞"),
        types.KeyboardButton("–ü—Ä–æ—Ñ–∏–ª—å"),
    )
    kb.add(
        types.KeyboardButton("–û—á–∏—Å—Ç–∏—Ç—å"),
        types.KeyboardButton("Lang üåê"),
    )
    return kb


@bot.message_handler(func=lambda m: m.text == "–ü—Ä–æ—Ñ–∏–ª—å")
def show_profile(m):
    cmd_profile(m)


@bot.message_handler(func=lambda m: m.text == "–ú–µ–¥–∏–∞")
def show_media(m):
    cmd_media(m)

# --- –†–∞–±–æ—Ç–∞ —Å —è–∑—ã–∫–æ–º ---


def set_language(chat_id: int, lang: str) -> None:
    try:
        r.set(f"lang:{chat_id}", lang, ex=TTL)
    except Exception:
        pass
    _language_cache[chat_id] = lang


def get_language(chat_id: int) -> str:
    try:
        lang = r.get(f"lang:{chat_id}")
    except Exception:
        lang = None

    if lang:
        if isinstance(lang, bytes):
            lang = lang.decode("utf-8")
        _language_cache[chat_id] = str(lang)
        return str(lang)

    return _language_cache.get(chat_id, "ru")

# --- –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---

def get_user_mode(chat_id: int) -> str:
    if is_owner(chat_id):
        return "philosopher"
    return "short_friend"

# --- –†–µ–∂–∏–º—ã –æ–±—â–µ–Ω–∏—è ---

MODES = {
    "short_friend": {
        "name": "–ö–æ—Ä–æ—Ç–∫–∏–π –¥—Ä—É–≥",
        # –ù–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç: –¥—Ä—É–≥ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ —á–µ—Å—Ç–Ω–æ,
        # –Ω–µ –∑–∞–¥–∞—ë—Ç –ª–∏—à–Ω–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –Ω–µ —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ –≤–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.
        "system_prompt": (
            "–ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —Ç—ã –º–æ–π –¥—Ä—É–≥ –∏ –ø–æ–º–æ—â–Ω–∏–∫. –Ø –±—É–¥—É –¥–µ–ª–∏—Ç—å—Å—è —Å–æ–±—ã—Ç–∏—è–º–∏ –∏ "
            "–∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã, –∞ —Ç—ã –æ—Ç–≤–µ—á–∞–π —á–µ—Å—Ç–Ω–æ, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–µ. "
            "–ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–∞–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –º–æ–∏ –≤–æ–ø—Ä–æ—Å—ã. –ù–µ –≤—Å—Ç–∞–≤–ª—è–π "
            "—Å—Å—ã–ª–æ–∫ –Ω–∞ –≤–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –≤–æ–ø—Ä–æ—Å."
        ),
    },
    "philosopher": {
        "name": "–§–∏–ª–æ—Å–æ—Ñ",
        # –ù–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç: —Ñ–∏–ª–æ—Å–æ—Ñ –æ—Ç–≤–µ—á–∞–µ—Ç –≥–ª—É–±–æ–∫–æ, –Ω–æ —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏,
        # –Ω–µ —Å—Å—ã–ª–∞—è—Å—å –Ω–∞ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –∏ –Ω–µ –æ—Ç–∫–∞–∑—ã–≤–∞—è—Å—å –æ—Ç –æ—Ç–≤–µ—Ç–∞.
        "system_prompt": (
            "–ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —Ç—ã –º—É–¥—Ä—ã–π —Ñ–∏–ª–æ—Å–æ—Ñ. –Ø –±—É–¥—É –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –æ –∂–∏–∑–Ω–∏ –∏ –º–∏—Ä–µ. "
            "–¢—ã –æ—Ç–≤–µ—á–∞–π, –∏—Å—Å–ª–µ–¥—É—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ —Ç–µ–æ—Ä–∏–∏, –ø—Ä–µ–¥–ª–∞–≥–∞–π –≥–ª—É–±–æ–∫–∏–µ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è "
            "–∏ –Ω–æ–≤—ã–µ –∏–¥–µ–∏, –Ω–æ –±–µ–∑ —Å—Å—ã–ª–æ–∫ –Ω–∞ –≤–Ω–µ—à–Ω–∏–µ —Ä–µ—Å—É—Ä—Å—ã. –î–∞–∂–µ –µ—Å–ª–∏ —Ç–µ–º–∞ —Å–ª–æ–∂–Ω–∞, "
            "–¥–∞–π —Å–≤–æ–π –æ—Ç–≤–µ—Ç, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –∑–Ω–∞–Ω–∏—è –∏ –ª–æ–≥–∏–∫—É."
        ),
    },
    "academic": {
        "name": "–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π",
        # –ù–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç: –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –æ–±—ä—è—Å–Ω—è–µ—Ç —Ç–µ–º—ã —è—Å–Ω–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ,
        # –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏—Å–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ —Å—Ç–æ—Ä–æ–Ω—É.
        "system_prompt": (
            "–ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —Ç—ã –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∏ –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫. –ù–∞ –º–æ–∏ –≤–æ–ø—Ä–æ—Å—ã –æ—Ç–≤–µ—á–∞–π "
            "—è—Å–Ω–æ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ –∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É—è –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏ "
            "–ø—Ä–∏–º–µ—Ä—ã. –ü–æ–º–æ–≥–∏ –ø–æ–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ —Ç–µ–º—ã, —Ä–∞–∑–±–∏–≤–∞—è –∏—Ö –Ω–∞ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–µ —á–∞—Å—Ç–∏. "
            "–ù–µ –≤—Å—Ç–∞–≤–ª—è–π —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –Ω–µ –æ—Ç–∫–∞–∑—ã–≤–∞–π—Å—è –æ—Ç –æ—Ç–≤–µ—Ç–∞."
        ),
    },
}

# --- GPT-5 Mini –æ—Ç–≤–µ—Ç —Å –ø–æ—Ç–æ–∫–æ–≤–æ–π –≤—ã–¥–∞—á–µ–π ---

EDIT_INTERVAL = 0.4             # –Ω–µ —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (—Å–µ–∫)
FIRST_CHUNK_TOKENS = 12         # –ø–æ–∫–∞–∑–∞—Ç—å –±—ã—Å—Ç—Ä–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω–æ–≤
STREAM_STALL_TIMEOUT = 30.0     # —É–≤–µ–ª–∏—á–∏–ª–∏ —Å 12.0, –¥–∞—ë–º —Å—Ç—Ä–∏–º—É –¥–æ 30 —Å–µ–∫—É–Ω–¥ —Ç–∏—à–∏–Ω—ã
MAX_RETRIES = 3                 # —É–≤–µ–ª–∏—á–∏–ª–∏ —á–∏—Å–ª–æ –ø–æ–ø—ã—Ç–æ–∫ —Å 2 –¥–æ 3
BACKOFF_BASE = 1.0              # –±–∞–∑–æ–≤–∞—è –ø–∞—É–∑–∞ –ø—Ä–∏ retry (—Å–µ–∫)

# --- –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ ---
# –°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –≤ GPT.
CONTEXT_MESSAGES = 4

# –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ –ø–æ chat_id ‚Äî –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–∏–º—ã –≤ –æ–¥–Ω–æ–º —á–∞—Ç–µ.
_chat_locks: dict[int, Lock] = {}
_logger = logging.getLogger("synteragpt.stream")
_logger.setLevel(logging.INFO)
Path("/root/SynteraGPT/logs").mkdir(parents=True, exist_ok=True)
# –Ω–∞—Å—Ç—Ä–æ–∏–º –ø—Ä–æ—Å—Ç–æ–π file handler (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
fh = logging.FileHandler("/root/SynteraGPT/logs/stream_gpt.log")
fh.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(message)s"))
_logger.addHandler(fh)



def ask_gpt(
    messages: list[dict],
    *,
    max_tokens: int | None = None,
    tools: list[dict] | None = None,
    on_chunk: Callable[[str], None] | None = None,
) -> str:
    """Stream a response from the Responses API and optionally emit partial chunks."""

    kwargs: dict = {
        "model": CHAT_MODEL,
        "input": prepare_responses_input(messages),
        "stream": True,
    }
    if max_tokens is not None:
        kwargs["max_output_tokens"] = max_tokens
    if tools:
        kwargs["tools"] = tools

    stream = client.responses.create(**kwargs)
    collected: list[str] = []
    final_response = None

    try:
        for event in stream:
            event_type = getattr(event, "type", "")
            if event_type in {"response.output_text.delta", "response.message.delta"}:
                chunk = coerce_content_to_text(getattr(event, "delta", None))
                if chunk:
                    collected.append(chunk)
                    if on_chunk is not None:
                        try:
                            on_chunk(chunk)
                        except Exception:
                            pass
            elif event_type == "response.error":
                error = getattr(event, "error", None)
                message = getattr(error, "message", None) or str(error)
                raise RuntimeError(message)
            elif event_type == "response.completed":
                with suppress(Exception):
                    final_response = stream.get_final_response()

        if final_response is None:
            with suppress(Exception):
                final_response = stream.get_final_response()
    finally:
        close = getattr(stream, "close", None)
        if callable(close):
            with suppress(Exception):
                close()

    text = ""
    if final_response is not None:
        text = extract_response_text(final_response) or ""
    if not text:
        text = "".join(collected)
    return text.strip()

def _get_chat_lock(chat_id: int) -> Lock:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–∏ —Å–æ–∑–¥–∞—ë—Ç –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏) Lock –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —á–∞—Ç–∞."""
    lock = _chat_locks.get(chat_id)
    if lock is None:
        lock = Lock()
        _chat_locks[chat_id] = lock
    return lock


def stream_gpt_answer(
    chat_id: int,
    user_text: str,
    mode_key: str = "short_friend",
    *,
    force_web: bool = False,
    allow_web_fallback: bool = False,
) -> None:
    """Stream a GPT-5 mini answer and optionally fall back to web search."""

    lock = _get_chat_lock(chat_id)
    if not lock.acquire(blocking=False):
        with suppress(Exception):
            bot.send_message(chat_id, "‚ö†Ô∏è –£–∂–µ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –æ—Ç–≤–µ—Ç –≤ —ç—Ç–æ–º —á–∞—Ç–µ. –ü–æ–¥–æ–∂–¥–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")
        return

    try:
        _ensure_history_cached(chat_id)

        history = user_histories.setdefault(chat_id, [])
        history.append({"role": "user", "content": user_text})

        language = get_language(chat_id)
        mode_prompt = MODES[mode_key]["system_prompt"]
        system_prompt = (
            f"{SYSTEM_PROMPT}\n\n{mode_prompt}\n\n–û—Ç–≤–µ—á–∞–π –Ω–∞ —è–∑—ã–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {language}."
        )
        context_history = history[-CONTEXT_MESSAGES:]
        messages = [{"role": "system", "content": system_prompt}] + context_history

        cache_key = (chat_id, user_text.strip().lower())
        use_cache = not force_web
        cached = response_cache.get(cache_key) if use_cache else None
        if cached:
            show_typing(chat_id)
            draft = bot.send_message(chat_id, "‚Ä¶", reply_markup=main_menu())
            msg_id = draft.message_id
            safe_cached = sanitize_for_telegram(cached)
            try:
                bot.edit_message_text(safe_cached or cached, chat_id, msg_id, parse_mode="HTML")
            except Exception:
                with suppress(Exception):
                    bot.send_message(chat_id, safe_cached or cached, parse_mode="HTML")
            history.append({"role": "assistant", "content": cached})
            trimmed = history[-HISTORY_LIMIT:]
            user_histories[chat_id] = trimmed
            with suppress(Exception):
                save_history(chat_id, trimmed)
            return

        show_typing(chat_id)
        draft = bot.send_message(chat_id, "‚Ä¶", reply_markup=main_menu())
        msg_id = draft.message_id
        message_failed = False

        if force_web:
            try:
                web_raw = ask_gpt_web(user_text).strip()
            except Exception:
                if history and history[-1].get("role") == "user" and history[-1].get("content") == user_text:
                    history.pop()
                failure_text = "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –ø–æ–∑–∂–µ."
                safe_failure = sanitize_for_telegram(failure_text)
                try:
                    bot.edit_message_text(safe_failure or failure_text, chat_id, msg_id, parse_mode="HTML")
                except Exception:
                    with suppress(Exception):
                        bot.send_message(chat_id, safe_failure or failure_text, parse_mode="HTML")
                return

            final_text = sanitize_model_output(web_raw)
            if not final_text:
                final_text = "üòî –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –ü–æ–ø—Ä–æ–±—É–π —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å."

            safe_text = sanitize_for_telegram(final_text)
            try:
                bot.edit_message_text(safe_text or final_text, chat_id, msg_id, parse_mode="HTML")
            except Exception:
                with suppress(Exception):
                    bot.send_message(chat_id, safe_text or final_text, parse_mode="HTML")

            history.append({"role": "assistant", "content": final_text})
            trimmed_history = history[-HISTORY_LIMIT:]
            user_histories[chat_id] = trimmed_history
            try:
                save_history(chat_id, trimmed_history)
            except Exception:
                _logger.exception("Failed to persist chat history")

            response_cache[cache_key] = final_text
            return

        partial_chunks: list[str] = []
        start_time = time.monotonic()
        last_edit = start_time
        first_chunk_sent = False

        def handle_chunk(chunk: str) -> None:
            nonlocal last_edit, first_chunk_sent, message_failed
            if not chunk:
                return

            partial_chunks.append(chunk)
            aggregated_raw = "".join(partial_chunks)
            safe_partial = sanitize_for_telegram(aggregated_raw)
            if not safe_partial:
                return

            now = time.monotonic()
            should_update = False
            if not first_chunk_sent:
                cleaned_length = len(sanitize_model_output(aggregated_raw))
                if cleaned_length >= FIRST_CHUNK_TOKENS or now - start_time >= EDIT_INTERVAL:
                    should_update = True
            elif now - last_edit >= EDIT_INTERVAL:
                should_update = True

            if should_update and not message_failed:
                try:
                    bot.edit_message_text(safe_partial, chat_id, msg_id, parse_mode="HTML")
                    first_chunk_sent = True
                    last_edit = now
                except Exception:
                    message_failed = True

        error_occurred = False
        try:
            final_text = ask_gpt(messages, on_chunk=handle_chunk)
        except Exception:
            error_occurred = True
            final_text = ""
            _logger.exception("Failed to stream response")

        aggregated_raw = "".join(partial_chunks)

        if error_occurred:
            if history and history[-1].get("role") == "user" and history[-1].get("content") == user_text:
                history.pop()
            failure_text = "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –ø–æ–∑–∂–µ."
            safe_failure = sanitize_for_telegram(failure_text)
            if not message_failed:
                try:
                    bot.edit_message_text(safe_failure or failure_text, chat_id, msg_id, parse_mode="HTML")
                except Exception:
                    message_failed = True
            if message_failed:
                with suppress(Exception):
                    bot.send_message(chat_id, safe_failure or failure_text, parse_mode="HTML")
            return

        if not final_text:
            final_text = aggregated_raw

        final_text = sanitize_model_output(final_text)

        used_web = False
        if allow_web_fallback and should_escalate_to_web(user_text, final_text):
            try:
                if not message_failed:
                    try:
                        bot.edit_message_text(
                            "üåê –ò—â—É —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ‚Ä¶", chat_id, msg_id, parse_mode="HTML"
                        )
                    except Exception:
                        message_failed = True
                web_raw = ask_gpt_web(user_text).strip()
            except Exception:
                web_raw = ""

            if web_raw:
                new_final = sanitize_model_output(web_raw)
                if new_final:
                    final_text = new_final
                    used_web = True

        if not final_text:
            final_text = "‚ö†Ô∏è –û—Ç–≤–µ—Ç –ø—É—Å—Ç."

        final_text = replace_foreign_links_with_ru(final_text)

        if used_web:
            response_cache.pop(cache_key, None)

        safe_text = sanitize_for_telegram(final_text)
        if not message_failed:
            try:
                bot.edit_message_text(safe_text or final_text, chat_id, msg_id, parse_mode="HTML")
            except Exception:
                message_failed = True
        if message_failed:
            with suppress(Exception):
                bot.send_message(chat_id, safe_text or final_text, parse_mode="HTML")

        history.append({"role": "assistant", "content": final_text})
        trimmed_history = history[-HISTORY_LIMIT:]
        user_histories[chat_id] = trimmed_history
        try:
            save_history(chat_id, trimmed_history)
        except Exception:
            _logger.exception("Failed to persist chat history")

        response_cache[cache_key] = final_text

    finally:
        with suppress(Exception):
            lock.release()

# --- –•—ç–Ω–¥–ª–µ—Ä—ã ---
@bot.message_handler(commands=["start"])
def start(m):
    send_welcome_menu(m.chat.id)


@bot.message_handler(commands=["publish"])
def publish(m):
    if not is_owner(m.from_user.id):
        bot.reply_to(m, "‚ùå –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞—Ä—Ç–æ–≤–æ–≥–æ –æ–∫–Ω–∞.")
        return

    try:
        send_start_window(CHANNEL_USERNAME)
    except Exception as exc:
        bot.reply_to(m, f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—Ç–æ–≤–æ–µ –æ–∫–Ω–æ: {exc}")
        return

    bot.send_message(
        m.chat.id,
        "–°—Ç–∞—Ä—Ç–æ–≤–æ–µ –æ–∫–Ω–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ –≤ –∫–∞–Ω–∞–ª–µ. –ó–∞–∫—Ä–µ–ø–∏ –µ–≥–æ –≤—Ä—É—á–Ω—É—é.",
    )


@bot.message_handler(func=lambda msg: msg.text == "–û—á–∏—Å—Ç–∏—Ç—å")
def cmd_clear(msg):
    clear_history(msg.chat.id)
    user_histories.pop(msg.chat.id, None)
    user_messages.pop(msg.chat.id, None)

    send_and_store(msg.chat.id, "üßπ –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞", reply_markup=main_menu())


@bot.message_handler(func=lambda msg: msg.text and msg.text.startswith("Lang"))
def cmd_language(msg):
    kb = types.InlineKeyboardMarkup()
    kb.add(types.InlineKeyboardButton("–†—É—Å—Å–∫–∏–π üá∑üá∫", callback_data="lang_ru"))
    kb.add(types.InlineKeyboardButton("English üá¨üáß", callback_data="lang_en"))
    kb.add(types.InlineKeyboardButton("‰∏≠Êñá üá®üá≥", callback_data="lang_zh"))

    bot.send_message(msg.chat.id, "üåê Choose your language:", reply_markup=kb)


@bot.callback_query_handler(func=lambda call: call.data.startswith("lang_"))
def on_language_change(call):
    lang = call.data.split("_", 1)[1]
    set_language(call.message.chat.id, lang)

    names = {"ru": "–†—É—Å—Å–∫–∏–π üá∑üá∫", "en": "English üá¨üáß", "zh": "‰∏≠Êñá üá®üá≥"}
    chosen = names.get(lang, lang)
    bot.answer_callback_query(call.id, f"Language set: {chosen}")
    send_and_store(call.message.chat.id, f"‚úÖ Now I will talk in {chosen}", reply_markup=main_menu())

@bot.message_handler(
    func=lambda msg: any(
        word in msg.text.lower()
        for word in [
            "–∫—Ç–æ —Ç—ã",
            "—á—Ç–æ —Ç—ã",
            "–∫–∞–∫–∞—è –≤–µ—Ä—Å–∏—è",
            "—Ç–≤–æ—è –≤–µ—Ä—Å–∏—è",
            "–≤–µ—Ä—Å–∏—è –≥–ø—Ç",
            "–∫–∞–∫–∞—è –º–æ–¥–µ–ª—å",
            "—Ç–≤–æ—è –º–æ–¥–µ–ª—å",
            "–º–æ–¥–µ–ª—å –≥–ø—Ç",
            "—Å—Ç—Ä—É–∫—Ç—É—Ä–∞",
            "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞",
            "gpt",
        ]
    )
)
def who_are_you(m):
    text = (
        "–Ø —Ä–∞–±–æ—Ç–∞—é –Ω–∞ –±–∞–∑–µ GPT-5 Mini, –Ω–æ–≤–µ–π—à–µ–π –∫–æ–º–ø–∞–∫—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏. "
        "GPT-5 Mini –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≥–ª—É–±–æ–∫—É—é –ø—Ä–æ—Ä–∞–±–æ—Ç–∫—É –¥–∏–∞–ª–æ–≥–∞, –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å "
        "–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å, –æ–ø–∏—Ä–∞–µ—Ç—Å—è –Ω–∞ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è. "
        "–ú–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ —Å—Ç–∏–ª–∏ –æ–±—â–µ–Ω–∏—è: –ö–æ—Ä–æ—Ç–∫–∏–π –¥—Ä—É–≥, –§–∏–ª–æ—Å–æ—Ñ –∏ –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π. "
        "–û–Ω–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –≤–µ—Å—Ç–∏ –∂–∏–≤–æ–π —Ä–∞–∑–≥–æ–≤–æ—Ä, –¥–∞–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã "
        "–∏ –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏. "
        "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPT-5 Mini –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ –æ—Ç–≤–µ—Ç—ã, "
        "–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥–∞—é—Ç –≤ —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑–µ –∏ –ø—Ä–∏–Ω—è—Ç–∏–∏ —Ä–µ—à–µ–Ω–∏–π."
    )
    bot.send_message(m.chat.id, text, reply_markup=main_menu())

# --- –§–æ–Ω–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫–æ–Ω—á–∞–Ω–∏–π –ø–æ–¥–ø–∏—Å–æ–∫ –∏ –æ—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ ---
def background_checker():
    counter = 1
    while True:
        if counter % 7 == 0:
            # –û—á–∏—â–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞: –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π, –∫—ç—à –æ—Ç–≤–µ—Ç–æ–≤ –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            user_histories.clear()
            response_cache.clear()
            for chat_id, msgs in user_messages.items():
                for msg_id in msgs:
                    try:
                        bot.delete_message(chat_id, msg_id)
                    except Exception:
                        pass
            user_messages.clear()
            for chat_id in iter_history_chat_ids():
                clear_history(chat_id)
            print("üßπ –ò—Å—Ç–æ—Ä–∏—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—á–∏—â–µ–Ω—ã")

        counter += 1
        time.sleep(86400)  # —Ä–∞–∑ –≤ —Å—É—Ç–∫–∏

# --- fallback ‚Äî –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–µ —Å–æ–≤–ø–∞–ª —Å –º–µ–Ω—é, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ GPT ---
@bot.message_handler(
    func=lambda msg: bool(getattr(msg, "text", "")) and not msg.text.startswith("/")
)
def fallback(m):
    mode = get_user_mode(m.chat.id)
    prefer_web = should_prefer_web(m.text)
    stream_gpt_answer(
        m.chat.id,
        m.text,
        mode,
        force_web=prefer_web,
        allow_web_fallback=not prefer_web,
    )

# --- –ó–∞–ø—É—Å–∫ ---
if __name__ == "__main__":
    from worker_media import start_media_worker

    start_media_worker()
    threading.Thread(target=background_checker, daemon=True).start()

    while True:
        try:
            bot.polling(
                none_stop=True,
                timeout=60,
                long_polling_timeout=60,
                skip_pending=True,
            )
        except Exception as exc:  # noqa: BLE001 - —Ö–æ—Ç–∏–º –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –ª—é–±—ã–µ —Å–±–æ–∏
            log_exception(exc)



