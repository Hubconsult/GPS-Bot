"""–ê–≤—Ç–æ–ø–æ—Å—Ç–∏–Ω–≥ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –∫–∞–Ω–∞–ª–æ–≤ Syntera."""

from __future__ import annotations

import base64
import json
import random
import traceback
from contextlib import suppress
from datetime import datetime
from io import BytesIO
from pathlib import Path
from typing import Optional, Tuple

from PIL import Image, UnidentifiedImageError
from telebot import types

from openai_adapter import extract_response_text, prepare_responses_input
from settings import (
    CHAT_MODEL,
    OWNER_ID,
    bot,
    client as openai_client,
)

CHANNEL_ID = "@SynteraAI"
GROUP_ID = "@HubConsult"
BOT_LINK = "https://t.me/SynteraGPT_bot"
BANER_PATH = Path(__file__).resolve().parent / "baner_dlya_perehoda.png"

SCENARIOS = [
    "–†–∞—Å—Å–∫–∞–∂–∏ –º–∏–Ω–∏-–∏—Å—Ç–æ—Ä–∏—é –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—è, –∫–æ—Ç–æ—Ä—ã–π —Å –ø–æ–º–æ—â—å—é –±–æ—Ç–∞ —É—Å–∫–æ—Ä–∏–ª –∑–∞–ø—É—Å–∫ –ø—Ä–æ–¥—É–∫—Ç–∞",
    "–°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ —Å–≤–µ–∂–µ–π –∏—Å—Ç–æ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞ –∏–∑ –º–∏—Ä–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –∏ —Å–≤—è–∂–∏ –µ—ë —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ SynteraGPT",
    "–û–ø–∏—à–∏, –∫–∞–∫ –∫–æ–º–∞–Ω–¥–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ—Ç–∞ –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –æ—Ç—á—ë—Ç–æ–≤",
    "–ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏—â–µ—Ç –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–¥–µ–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –Ω–∞—Ö–æ–¥–∏—Ç –∏—Ö —á–µ—Ä–µ–∑ SynteraGPT",
    "–°–¥–µ–ª–∞–π –∞–∫—Ü–µ–Ω—Ç –Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ AI Systems –∏ –∂–∏–≤–æ–º –æ–±—â–µ–Ω–∏–∏ –≤ Hubconsult",
    "–ü–æ–∫–∞–∂–∏, –∫–∞–∫ SynteraGPT –ø–æ–º–æ–≥–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä—É—Ç–∏–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –ø–æ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É",
    "–û–ø–∏—à–∏ —É—Ç—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π —ç–∫–æ–Ω–æ–º–∏—Ç –≤—Ä–µ–º—è –±–ª–∞–≥–æ–¥–∞—Ä—è –±—ã—Å—Ç—Ä—ã–º –æ—Ç–≤–µ—Ç–∞–º –∏ –ø–æ–∏—Å–∫—É —Å SynteraGPT",
]

DEFAULT_IMAGE_PROMPT = (
    "–§—É—Ç—É—Ä–∏—Å—Ç–∏—á–Ω—ã–π –±–∞–Ω–Ω–µ—Ä –¥–ª—è Telegram-–ø–æ—Å—Ç–∞ –æ SynteraGPT: –Ω–µ–æ–Ω–æ–≤—ã–µ –∞–∫—Ü–µ–Ω—Ç—ã, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, "
    "–¥—Ä—É–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å."
)
FALLBACK_IMAGE = Path(__file__).resolve().parent / "syntera_logo.png"

_last_scenario: Optional[str] = None


def _pick_scenario() -> str:
    global _last_scenario

    scenario = random.choice(SCENARIOS)
    if _last_scenario and len(SCENARIOS) > 1:
        attempts = 0
        while scenario == _last_scenario and attempts < 5:
            scenario = random.choice(SCENARIOS)
            attempts += 1
    _last_scenario = scenario
    return scenario


def _parse_json_payload(raw: str) -> Tuple[str, str]:
    data = json.loads(raw)
    post_text = (data.get("post") or "").strip()
    image_prompt = (data.get("image_prompt") or "").strip()
    if not post_text:
        raise ValueError("Empty post text")
    return post_text, image_prompt


def _generate_post_payload(mode: str) -> Tuple[str, str]:
    scenario = _pick_scenario()
    today = datetime.now().strftime("%d.%m.%Y")
    length_instruction = {
        "short": "–°–æ–∑–¥–∞–π –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π, –∂–∏–≤–æ–π –ø–æ—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—â—É—â–∞–µ—Ç—Å—è –∫–æ—Ä–æ—Ç–∫–∏–º ‚Äî –≤—ã–±–∏—Ä–∞–π –¥–ª–∏–Ω—É —Å–∞–º, –Ω–æ –∏–∑–±–µ–≥–∞–π –æ–¥–Ω–æ–æ–±—Ä–∞–∑–∏—è.",
        "long": "–°–æ–∑–¥–∞–π —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –ø–æ—Å—Ç —Å –ø–ª–∞–≤–Ω—ã–º —Ä–∞–∑–≤–∏—Ç–∏–µ–º –º—ã—Å–ª–∏. –î–µ–ª–∞–π –µ–≥–æ –¥–µ—Ç–∞–ª—å–Ω—ã–º –∏ –∞—Ç–º–æ—Å—Ñ–µ—Ä–Ω—ã–º –±–µ–∑ —Å—Ç—Ä–æ–≥–∏—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –¥–ª–∏–Ω–µ.",
    }.get(mode, "–°–æ–∑–¥–∞–π —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç —Å –±–æ–≥–∞—Ç–æ–π –ø–æ–¥–∞—á–µ–π –∏ —Å–≤–æ–±–æ–¥–Ω–æ–π –¥–ª–∏–Ω–æ–π.")

    system_prompt = (
        "–¢—ã ‚Äî –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä Telegram-–∫–∞–Ω–∞–ª–∞ SynteraGPT. –ö–∞–∂–¥—ã–π —Ç–µ–∫—Å—Ç —É–Ω–∏–∫–∞–ª–µ–Ω, "
        "–∏–≥—Ä–∞–µ—Ç —Å –∏–Ω—Ç–æ–Ω–∞—Ü–∏—è–º–∏ –∏ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–µ—Ç –≤—ã–≥–æ–¥—ã –±–æ—Ç–∞. –í—Å—Ç–∞–≤–ª—è–π –º–∞–∫—Å–∏–º—É–º –¥–≤–∞ —ç–º–æ–¥–∑–∏, –µ—Å–ª–∏ –æ–Ω–∏ —É—Å–∏–ª–∏–≤–∞—é—Ç –ø–æ–¥–∞—á—É, "
        "–Ω–æ –Ω–µ –¥–µ–ª–∞–π —ç—Ç–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º."
    )

    user_prompt = (
        f"–°–µ–≥–æ–¥–Ω—è {today}. {length_instruction}\n"
        f"–ò—Å–ø–æ–ª—å–∑—É–π –∫–∞–∫ –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ: {scenario}.\n"
        "–†–∞—Å—Å–∫–∞–∂–∏, —á–µ–º –ø–æ–ª–µ–∑–µ–Ω SynteraGPT: –¥–æ—Å—Ç—É–ø –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É, –∞–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞, –±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã.\n"
        "–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–ø–æ–º—è–Ω–∏, —á—Ç–æ —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø—É–±–ª–∏–∫—É—é—Ç—Å—è –≤ –∫–∞–Ω–∞–ª–µ AI Systems –∏ –≤ –≥—Ä—É–ø–ø–µ Hubconsult.\n"
        f"–î–æ–±–∞–≤—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–∏–∑—ã–≤ –ø–µ—Ä–µ–π—Ç–∏ –∫ –±–æ—Ç—É –ø–æ —Å—Å—ã–ª–∫–µ {BOT_LINK}.\n"
        "–ú–µ–Ω—è–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —á—Ç–æ–±—ã –∫–∞–∂–¥—ã–π –ø–æ—Å—Ç –æ—Ç–ª–∏—á–∞–ª—Å—è –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ.\n"
        "–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å –ø–æ–ª—è–º–∏ post –∏ image_prompt."
    )

    try:
        response = openai_client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            max_completion_tokens=500,
            temperature=0.85,
            presence_penalty=0.4,
            frequency_penalty=0.25,
        )
        payload = extract_response_text(response)
        return _parse_json_payload(payload)
    except Exception as exc:  # noqa: BLE001
        print("[POSTGEN] –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞:", exc)
        if mode == "short":
            return (
                "SynteraGPT –≤—Å–µ–≥–¥–∞ –ø–æ–¥ —Ä—É–∫–æ–π, —á—Ç–æ–±—ã –ø–æ–¥—Å–∫–∞–∑–∞—Ç—å –∏–¥–µ—é, –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ–∫—Å—Ç –∏–ª–∏ –Ω–∞–∫–∏–¥–∞—Ç—å –∫–æ–¥. "
                "–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è –Ω–∞ AI Systems, –∑–∞–≥–ª—è–¥—ã–≤–∞–π –≤ Hubconsult –∏ –∑–∞—Ö–æ–¥–∏ –∫ –±–æ—Ç—É, –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å!",
                DEFAULT_IMAGE_PROMPT,
            )
        return (
            (
                "SynteraGPT –ø–æ–º–æ–≥–∞–µ—Ç —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏ –≤ –ø–∞—Ä—É –∫–ª–∏–∫–æ–≤: –∏—â–µ—Ç —Ñ–∞–∫—Ç—ã –æ–Ω–ª–∞–π–Ω, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã, –ø–∏—à–µ—Ç –∫–æ–¥ –∏ –¥–µ—Ä–∂–∏—Ç –≤ —Ç–æ–Ω—É—Å–µ. "
                "–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è –Ω–∞ –∫–∞–Ω–∞–ª AI Systems, –æ–±—Å—É–∂–¥–∞–π —Å–≤–µ–∂–∏–µ –∫–µ–π—Å—ã –≤ Hubconsult –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ –±–æ—Ç—É SynteraGPT –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å!"
            ),
            DEFAULT_IMAGE_PROMPT,
        )


def _generate_news_payload() -> tuple[str, str, str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—É—é –Ω–æ–≤–æ—Å—Ç—å –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å —Ä–µ–∞–ª—å–Ω–æ–π —Å—Å—ã–ª–∫–æ–π."""

    today = datetime.now().strftime("%d.%m.%Y")

    system_prompt = (
        "–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä Telegram-–∫–∞–Ω–∞–ª–∞ SynteraGPT. "
        "–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç web_search, —á—Ç–æ–±—ã –Ω–∞—Ö–æ–¥–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –æ–± –ò–ò, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö. "
        "–í—ã–±–∏—Ä–∞–π —Å–≤–µ–∂—É—é, –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—É—é –ø—É–±–ª–∏–∫–∞—Ü–∏—é –∏–∑ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (Reuters, MIT Tech Review, Wired, The Verge, N+1, TAdviser –∏ –¥—Ä.). "
        "–°–æ–∑–¥–∞–π —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª ‚Äî 4‚Äì8 –∞–±–∑–∞—Ü–µ–≤ ‚Äî —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º —Å—É—Ç–∏, –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–π –∏ –º–Ω–µ–Ω–∏–π —ç–∫—Å–ø–µ—Ä—Ç–æ–≤. "
        "–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∂–∏ —Å—Å—ã–ª–∫—É –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ (–≤ –ø–æ–ª–µ url). –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –Ω–æ–≤–æ—Å—Ç–∏."
    )

    user_prompt = (
        f"–°–µ–≥–æ–¥–Ω—è {today}. –ù–∞–π–¥–∏ —Å–∞–º—É—é –∏–Ω—Ç–µ—Ä–µ—Å–Ω—É—é –∏ –≤–∞–∂–Ω—É—é –Ω–æ–≤–æ—Å—Ç—å –æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö, –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ –∏–ª–∏ –Ω–∞—É–∫–µ. "
        "–°–æ—Å—Ç–∞–≤—å —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π —Ç–µ–∫—Å—Ç, –æ—Ñ–æ—Ä–º–∏ –∫–∞–∫ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç—å—é –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞. "
        "–î–æ–±–∞–≤—å –≤ –∫–æ–Ω—Ü–µ —Å—Å—ã–ª–∫—É –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫. "
        "–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å –ø–æ–ª—è–º–∏: headline, post, url."
    )

    try:
        response = openai_client.responses.create(
            model=CHAT_MODEL,
            input=prepare_responses_input(
                [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ]
            ),
            tools=[{"type": "web_search"}],
            response_format={"type": "json_object"},
            max_output_tokens=2000,
            temperature=0.75,
        )

        payload = extract_response_text(response)
        data = json.loads(payload)

        headline = (data.get("headline") or "–ù–æ–≤–æ—Å—Ç–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π").strip()
        post_text = (data.get("post") or "").strip()
        news_url = (data.get("url") or "").strip()

        if not news_url.startswith("http"):
            raise ValueError("URL –Ω–µ –Ω–∞–π–¥–µ–Ω")

        print(f"[NEWS] –ò—Å—Ç–æ—á–Ω–∏–∫: {news_url}")

        return headline, post_text, news_url

    except Exception as exc:  # noqa: BLE001
        print("[POSTGEN] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –Ω–æ–≤–æ—Å—Ç–∏:", exc)
        return (
            "SynteraGPT | –ù–æ–≤–æ—Å—Ç–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π",
            (
                "–°–µ–≥–æ–¥–Ω—è SynteraGPT –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –¥–µ–ª–∏—Ç—å—Å—è —Å–≤–µ–∂–∏–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏ –∏–∑ –º–∏—Ä–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –∏ –∏–Ω–Ω–æ–≤–∞—Ü–∏–π. "
                "–°–ª–µ–¥–∏—Ç–µ –∑–∞ –Ω–∞—à–∏–º–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏—è–º–∏, —á—Ç–æ–±—ã —É–∑–Ω–∞–≤–∞—Ç—å –ø–µ—Ä–≤—ã–º–∏ –æ –Ω–æ–≤—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö –ò–ò –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –±—É–¥—É—â–µ–≥–æ."
            ),
            "https://synteragpt.ai/news",
        )


def _normalize_image(image_bytes: bytes) -> Optional[bytes]:
    try:
        with Image.open(BytesIO(image_bytes)) as img:
            if img.mode not in {"RGB", "L"}:
                img = img.convert("RGB")
            buffer = BytesIO()
            img.save(buffer, format="JPEG", quality=90, optimize=True)
            return buffer.getvalue()
    except (UnidentifiedImageError, OSError):
        return None


def _generate_image_bytes(image_prompt: str) -> Optional[bytes]:
    prompt = image_prompt or DEFAULT_IMAGE_PROMPT
    try:
        result = openai_client.images.generate(
            prompt=prompt,
            size="512x512",  # —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            quality="standard",
        )
        b64 = None
        if result.data and len(result.data) > 0:
            b64 = result.data[0].b64_json
        if not b64:
            raise ValueError("Empty b64 data from API")

        raw = base64.b64decode(b64)
        if not raw or len(raw) < 10240:
            raise ValueError(f"Image too small: {len(raw)} bytes")

        normalized = _normalize_image(raw)
        if normalized:
            return normalized
        return raw
    except Exception as exc:  # noqa: BLE001
        print(f"[POSTGEN] –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {exc}")
        try:
            with FALLBACK_IMAGE.open("rb") as f:
                fb = f.read()
            return _normalize_image(fb) or fb
        except Exception as e2:  # noqa: BLE001
            print(f"[POSTGEN] Fallback —Ç–æ–∂–µ –Ω–µ —É–¥–∞–ª—Å—è: {e2}")
            return None


def _publish_post(message, caption: str, image_bytes: Optional[bytes]) -> None:
    kb = types.InlineKeyboardMarkup()
    kb.add(types.InlineKeyboardButton("–ü–µ—Ä–µ–π—Ç–∏ –∫ –±–æ—Ç—É", url=BOT_LINK))

    targets = [CHANNEL_ID, GROUP_ID]
    for target in targets:
        if image_bytes:
            buffer = BytesIO(image_bytes)
            buffer.name = "syntera_post.jpg"
            buffer.seek(0)
            try:
                bot.send_photo(
                    target,
                    buffer,
                    caption=caption,
                    parse_mode="HTML",
                    reply_markup=kb,
                )
            except Exception as e_photo:  # noqa: BLE001
                print(f"[POSTGEN] send_photo failed, try send_document: {e_photo}")
                buffer.seek(0)
                bot.send_document(
                    target,
                    buffer,
                    caption=caption,
                    parse_mode="HTML",
                    reply_markup=kb,
                )
        else:
            bot.send_message(
                target,
                caption,
                parse_mode="HTML",
                reply_markup=kb,
            )
    try:
        bot.reply_to(message, "‚úÖ –ü–æ—Å—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω.")
    except Exception:  # noqa: BLE001
        pass


def _handle_post_request(message, mode: str) -> None:
    user_id = getattr(message.from_user, "id", None)
    if user_id != OWNER_ID:
        bot.reply_to(message, "‚õî –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª—å—Ü—É.")
        return

    status_msg = bot.reply_to(message, "üß† –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∫–æ–Ω—Ç–µ–Ω—Ç, —ç—Ç–æ –∑–∞–π–º—ë—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥‚Ä¶")
    caption = ""
    image_bytes: Optional[bytes] = None

    try:
        if mode == "news":
            headline, post_text, news_url = _generate_news_payload()
            caption = (
                f"<b>{headline}</b>\n\n"
                f"{post_text}\n\n"
                f"üîó –ò—Å—Ç–æ—á–Ω–∏–∫: <a href='{news_url}'>{news_url}</a>\n\n"
                f"–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è –Ω–∞ –∫–∞–Ω–∞–ª AI Systems –∏ —É—á–∞—Å—Ç–≤—É–π –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏—è—Ö Hubconsult!"
            )
            if BANER_PATH.exists():
                with BANER_PATH.open("rb") as f:
                    image_bytes = f.read()
        else:
            text, image_prompt = _generate_post_payload(mode)
            caption = text
            image_bytes = _generate_image_bytes(image_prompt)

        _publish_post(message, caption, image_bytes)
    except Exception as exc:  # noqa: BLE001
        bot.reply_to(message, f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–æ—Å—Ç: {exc}")
        traceback.print_exc()
    finally:
        with suppress(Exception):
            bot.delete_message(status_msg.chat.id, status_msg.message_id)


@bot.message_handler(commands=["post_short"])
def create_short_post(message):
    _handle_post_request(message, "short")


@bot.message_handler(commands=["post_long"])
def create_long_post(message):
    _handle_post_request(message, "long")


@bot.message_handler(commands=["post_news"])
def create_news_post(message):
    _handle_post_request(message, "news")


__all__ = [
    "create_short_post",
    "create_long_post",
    "create_news_post",
]
