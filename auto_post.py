"""–ê–≤—Ç–æ–ø–æ—Å—Ç–∏–Ω–≥ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –∫–∞–Ω–∞–ª–æ–≤ Syntera."""

from __future__ import annotations

import base64
import json
import random
import re
import traceback
from collections import deque
from contextlib import suppress
from datetime import datetime
from io import BytesIO
from pathlib import Path
from typing import Optional, Tuple

from PIL import Image, UnidentifiedImageError
from telebot import types

from internet import ask_gpt_web  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à —Ä–∞–±–æ—á–∏–π –≤–µ–±-–ø–æ–∏—Å–∫

from openai_adapter import extract_response_text, prepare_responses_input
from settings import (
    CHAT_MODEL,
    OWNER_ID,
    bot,
    client as openai_client,
)

CHANNEL_ID = "@SynteraAI"
GROUP_ID = "@HubConsult"
BOT_LINK = "https://t.me/SynteraGPT_bot"
BANER_PATH = Path(__file__).resolve().parent / "baner_dlya_perehoda.png"

SCENARIOS = [
    "–†–∞—Å—Å–∫–∞–∂–∏ –º–∏–Ω–∏-–∏—Å—Ç–æ—Ä–∏—é –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—è, –∫–æ—Ç–æ—Ä—ã–π —Å –ø–æ–º–æ—â—å—é –±–æ—Ç–∞ —É—Å–∫–æ—Ä–∏–ª –∑–∞–ø—É—Å–∫ –ø—Ä–æ–¥—É–∫—Ç–∞",
    "–°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ —Å–≤–µ–∂–µ–π –∏—Å—Ç–æ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞ –∏–∑ –º–∏—Ä–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –∏ —Å–≤—è–∂–∏ –µ—ë —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ SynteraGPT",
    "–û–ø–∏—à–∏, –∫–∞–∫ –∫–æ–º–∞–Ω–¥–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ—Ç–∞ –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –æ—Ç—á—ë—Ç–æ–≤",
    "–ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏—â–µ—Ç –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–¥–µ–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –Ω–∞—Ö–æ–¥–∏—Ç –∏—Ö —á–µ—Ä–µ–∑ SynteraGPT",
    "–°–¥–µ–ª–∞–π –∞–∫—Ü–µ–Ω—Ç –Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ AI Systems –∏ –∂–∏–≤–æ–º –æ–±—â–µ–Ω–∏–∏ –≤ Hubconsult",
    "–ü–æ–∫–∞–∂–∏, –∫–∞–∫ SynteraGPT –ø–æ–º–æ–≥–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä—É—Ç–∏–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –ø–æ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É",
    "–û–ø–∏—à–∏ —É—Ç—Ä–æ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π —ç–∫–æ–Ω–æ–º–∏—Ç –≤—Ä–µ–º—è –±–ª–∞–≥–æ–¥–∞—Ä—è –±—ã—Å—Ç—Ä—ã–º –æ—Ç–≤–µ—Ç–∞–º –∏ –ø–æ–∏—Å–∫—É —Å SynteraGPT",
]

DEFAULT_IMAGE_PROMPT = (
    "–§—É—Ç—É—Ä–∏—Å—Ç–∏—á–Ω—ã–π –±–∞–Ω–Ω–µ—Ä –¥–ª—è Telegram-–ø–æ—Å—Ç–∞ –æ SynteraGPT: –Ω–µ–æ–Ω–æ–≤—ã–µ –∞–∫—Ü–µ–Ω—Ç—ã, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, "
    "–¥—Ä—É–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å."
)
FALLBACK_IMAGE = Path(__file__).resolve().parent / "syntera_logo.png"
_recent_news_topics: deque[str] = deque(maxlen=50)


def _read_banner_bytes() -> Optional[bytes]:
    try:
        with BANER_PATH.open("rb") as f:
            return f.read()
    except Exception:
        return None


def _extract_json_block(text: str) -> dict:
    """–î–æ—Å—Ç–∞—ë—Ç –ø–µ—Ä–≤—ã–π –≤–∞–ª–∏–¥–Ω—ã–π JSON-–æ–±—ä–µ–∫—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–æ–±–∞–≤–∏—Ç –ª–∏—à–Ω–∏–π —Ç–µ–∫—Å—Ç)."""

    try:
        return json.loads(text)
    except Exception:
        m = re.search(r"\{.*\}", text, flags=re.S)
        if not m:
            raise ValueError("JSON payload not found")
        return json.loads(m.group(0))

_last_scenario: Optional[str] = None


def _pick_scenario() -> str:
    global _last_scenario

    scenario = random.choice(SCENARIOS)
    if _last_scenario and len(SCENARIOS) > 1:
        attempts = 0
        while scenario == _last_scenario and attempts < 5:
            scenario = random.choice(SCENARIOS)
            attempts += 1
    _last_scenario = scenario
    return scenario


def _parse_json_payload(raw: str) -> Tuple[str, str]:
    data = json.loads(raw)
    post_text = (data.get("post") or "").strip()
    image_prompt = (data.get("image_prompt") or "").strip()
    if not post_text:
        raise ValueError("Empty post text")
    return post_text, image_prompt


def _generate_post_payload(mode: str) -> Tuple[str, str]:
    scenario = _pick_scenario()
    today = datetime.now().strftime("%d.%m.%Y")
    length_instruction = {
        "short": "–°–æ–∑–¥–∞–π –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π, –∂–∏–≤–æ–π –ø–æ—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—â—É—â–∞–µ—Ç—Å—è –∫–æ—Ä–æ—Ç–∫–∏–º ‚Äî –≤—ã–±–∏—Ä–∞–π –¥–ª–∏–Ω—É —Å–∞–º, –Ω–æ –∏–∑–±–µ–≥–∞–π –æ–¥–Ω–æ–æ–±—Ä–∞–∑–∏—è.",
        "long": "–°–æ–∑–¥–∞–π —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –ø–æ—Å—Ç —Å –ø–ª–∞–≤–Ω—ã–º —Ä–∞–∑–≤–∏—Ç–∏–µ–º –º—ã—Å–ª–∏. –î–µ–ª–∞–π –µ–≥–æ –¥–µ—Ç–∞–ª—å–Ω—ã–º –∏ –∞—Ç–º–æ—Å—Ñ–µ—Ä–Ω—ã–º –±–µ–∑ —Å—Ç—Ä–æ–≥–∏—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –¥–ª–∏–Ω–µ.",
    }.get(mode, "–°–æ–∑–¥–∞–π —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç —Å –±–æ–≥–∞—Ç–æ–π –ø–æ–¥–∞—á–µ–π –∏ —Å–≤–æ–±–æ–¥–Ω–æ–π –¥–ª–∏–Ω–æ–π.")

    system_prompt = (
        "–¢—ã ‚Äî –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä Telegram-–∫–∞–Ω–∞–ª–∞ SynteraGPT. –ö–∞–∂–¥—ã–π —Ç–µ–∫—Å—Ç —É–Ω–∏–∫–∞–ª–µ–Ω, "
        "–∏–≥—Ä–∞–µ—Ç —Å –∏–Ω—Ç–æ–Ω–∞—Ü–∏—è–º–∏ –∏ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–µ—Ç –≤—ã–≥–æ–¥—ã –±–æ—Ç–∞. –í—Å—Ç–∞–≤–ª—è–π –º–∞–∫—Å–∏–º—É–º –¥–≤–∞ —ç–º–æ–¥–∑–∏, –µ—Å–ª–∏ –æ–Ω–∏ —É—Å–∏–ª–∏–≤–∞—é—Ç –ø–æ–¥–∞—á—É, "
        "–Ω–æ –Ω–µ –¥–µ–ª–∞–π —ç—Ç–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–º."
    )

    user_prompt = (
        f"–°–µ–≥–æ–¥–Ω—è {today}. {length_instruction}\n"
        f"–ò—Å–ø–æ–ª—å–∑—É–π –∫–∞–∫ –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ: {scenario}.\n"
        "–†–∞—Å—Å–∫–∞–∂–∏, —á–µ–º –ø–æ–ª–µ–∑–µ–Ω SynteraGPT: –¥–æ—Å—Ç—É–ø –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É, –∞–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞, –±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã.\n"
        "–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–ø–æ–º—è–Ω–∏, —á—Ç–æ —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø—É–±–ª–∏–∫—É—é—Ç—Å—è –≤ –∫–∞–Ω–∞–ª–µ AI Systems –∏ –≤ –≥—Ä—É–ø–ø–µ Hubconsult.\n"
        f"–î–æ–±–∞–≤—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–∏–∑—ã–≤ –ø–µ—Ä–µ–π—Ç–∏ –∫ –±–æ—Ç—É –ø–æ —Å—Å—ã–ª–∫–µ {BOT_LINK}.\n"
        "–ú–µ–Ω—è–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —á—Ç–æ–±—ã –∫–∞–∂–¥—ã–π –ø–æ—Å—Ç –æ—Ç–ª–∏—á–∞–ª—Å—è –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ.\n"
        "–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å –ø–æ–ª—è–º–∏ post –∏ image_prompt."
    )

    try:
        response = openai_client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            max_completion_tokens=500,
            temperature=0.85,
            presence_penalty=0.4,
            frequency_penalty=0.25,
        )
        payload = extract_response_text(response)
        return _parse_json_payload(payload)
    except Exception as exc:  # noqa: BLE001
        print("[POSTGEN] –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞:", exc)
        if mode == "short":
            return (
                "SynteraGPT –≤—Å–µ–≥–¥–∞ –ø–æ–¥ —Ä—É–∫–æ–π, —á—Ç–æ–±—ã –ø–æ–¥—Å–∫–∞–∑–∞—Ç—å –∏–¥–µ—é, –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ–∫—Å—Ç –∏–ª–∏ –Ω–∞–∫–∏–¥–∞—Ç—å –∫–æ–¥. "
                "–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è –Ω–∞ AI Systems, –∑–∞–≥–ª—è–¥—ã–≤–∞–π –≤ Hubconsult –∏ –∑–∞—Ö–æ–¥–∏ –∫ –±–æ—Ç—É, –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å!",
                DEFAULT_IMAGE_PROMPT,
            )
        return (
            (
                "SynteraGPT –ø–æ–º–æ–≥–∞–µ—Ç —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏ –≤ –ø–∞—Ä—É –∫–ª–∏–∫–æ–≤: –∏—â–µ—Ç —Ñ–∞–∫—Ç—ã –æ–Ω–ª–∞–π–Ω, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã, –ø–∏—à–µ—Ç –∫–æ–¥ –∏ –¥–µ—Ä–∂–∏—Ç –≤ —Ç–æ–Ω—É—Å–µ. "
                "–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è –Ω–∞ –∫–∞–Ω–∞–ª AI Systems, –æ–±—Å—É–∂–¥–∞–π —Å–≤–µ–∂–∏–µ –∫–µ–π—Å—ã –≤ Hubconsult –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ –±–æ—Ç—É SynteraGPT –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å!"
            ),
            DEFAULT_IMAGE_PROMPT,
        )


def _generate_news_payload() -> Tuple[str, str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (headline, post_text, url) –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤–µ–±-–ø–æ–∏—Å–∫–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à –º–æ–¥—É–ª—å internet.ask_gpt_web, —á—Ç–æ–±—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –∏–¥—Ç–∏ –≤ —Å–µ—Ç—å.
    """

    avoided = ", ".join(list(_recent_news_topics)[-10:]) or "‚Äî"

    prompt = f"""
–ù–∞–π–¥–∏ –û–î–ù–£ —Ä–µ–∞–ª—å–Ω–æ —Å–≤–µ–∂—É—é (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 48 —á–∞—Å–æ–≤) –≤–∞–∂–Ω—É—é –Ω–æ–≤–æ—Å—Ç—å –æ–± –ò–ò/—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö/–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏.
–ò–∑–±–µ–≥–∞–π –ø–æ–≤—Ç–æ—Ä–æ–≤ —Ç–µ–º: {avoided}.
–í–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON:
{{
  "headline": "<–∫—Ä–∞—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ 120 —Å–∏–º–≤–æ–ª–æ–≤>",
  "post": "<—Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π —Ç–µ–∫—Å—Ç 4‚Äì8 –∞–±–∑–∞—Ü–µ–≤, —Ñ–∞–∫—Ç—ã, –∫–æ–Ω—Ç–µ–∫—Å—Ç, –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è, –±–µ–∑ –≤—ã–¥—É–º–æ–∫>",
  "url": "<–ü–†–Ø–ú–ê–Ø —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫ (–Ω–µ –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä, –Ω–µ —Å–æ—Ü—Å–µ—Ç–∏)>"
}}
–ù–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, —Ç–æ–ª—å–∫–æ JSON.
"""

    # 1) –ü—ã—Ç–∞–µ–º—Å—è —á–µ—Ä–µ–∑ –≤–∞—à –≤–µ–±‚Äë–ø–æ–∏—Å–∫
    raw = ask_gpt_web(prompt).strip()
    try:
        data = _extract_json_block(raw)
        headline = (data.get("headline") or "").strip()
        post_text = (data.get("post") or "").strip()
        url = (data.get("url") or "").strip()
        if not (headline and post_text and url.startswith("http")):
            raise ValueError("Incomplete web JSON")

        # –∑–∞–ø–æ–º–Ω–∏–º —Ç–µ–º—É –¥–ª—è –∞–Ω—Ç–∏‚Äë–ø–æ–≤—Ç–æ—Ä–æ–≤
        _recent_news_topics.append(headline.lower())
        return headline, post_text, url
    except Exception as exc:
        print(f"[POSTGEN] web-news parse failed: {exc}; raw={raw[:200]}")

    # 2) –§–æ–ª–±—ç–∫ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º Responses API —Å web_search (–µ—Å–ª–∏ —É –≤–∞—Å —Å–≤–µ–∂–∏–π openai)
    try:
        system_prompt = (
            "–¢—ã ‚Äî —Ä–µ–¥–∞–∫—Ç–æ—Ä —Ç–µ—Ö–Ω–æ‚Äë–∫–∞–Ω–∞–ª–∞. –ü–æ–ª—å–∑—É–π—Å—è web_search. –í–æ–∑–≤—Ä–∞—â–∞–π —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç—ã —Å —Å—Å—ã–ª–∫–æ–π."
        )
        user_prompt = (
            "–ù–∞–π–¥–∏ –æ–¥–Ω—É —Å–≤–µ–∂—É—é –∑–Ω–∞—á–∏–º—É—é –Ω–æ–≤–æ—Å—Ç—å –ø—Ä–æ –ò–ò/—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏/–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞ 48 —á–∞—Å–æ–≤. "
            f"–ò–∑–±–µ–≥–∞–π –ø–æ–≤—Ç–æ—Ä–æ–≤ —Ç–µ–º: {avoided}. –í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON {{\"headline\":\"...\",\"post\":\"...\",\"url\":\"...\"}}"
        )
        resp = openai_client.responses.create(
            model=CHAT_MODEL,
            input=prepare_responses_input([
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]),
            tools=[{"type": "web_search"}],
            response_format={"type": "json_object"},
            max_output_tokens=1800,
            temperature=0.7,
        )
        payload = extract_response_text(resp)
        data = _extract_json_block(payload)
        headline = (data.get("headline") or "").strip()
        post_text = (data.get("post") or "").strip()
        url = (data.get("url") or "").strip()
        if not (headline and post_text and url.startswith("http")):
            raise ValueError("web_search returned incomplete JSON")

        _recent_news_topics.append(headline.lower())
        return headline, post_text, url
    except Exception as exc:
        print(f"[POSTGEN] responses/web_search failed: {exc}")

    # 3) –§–æ–ª–±—ç–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∏–Ω—Å—Ç–∞–Ω—Ü–∏–∏ ‚Äî –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞
    return (
        "SynteraGPT | –ù–æ–≤–æ—Å—Ç–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π",
        "–ü–æ–∫–∞ –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–¥—ë–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Å–≤–µ–∂–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤. "
        "–ú—ã —Å–∫–æ—Ä–æ –≤–µ—Ä–Ω—ë–º—Å—è —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º —Ä–∞–∑–±–æ—Ä–æ–º –≤–∞–∂–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –∏–∑ –º–∏—Ä–∞ –ò–ò –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏.",
        "https://synteragpt.ai/news",
    )


def _normalize_image(image_bytes: bytes) -> Optional[bytes]:
    try:
        with Image.open(BytesIO(image_bytes)) as img:
            if img.mode not in {"RGB", "L"}:
                img = img.convert("RGB")
            buffer = BytesIO()
            img.save(buffer, format="JPEG", quality=90, optimize=True)
            return buffer.getvalue()
    except (UnidentifiedImageError, OSError):
        return None


def _generate_image_bytes(image_prompt: str) -> Optional[bytes]:
    prompt = image_prompt or DEFAULT_IMAGE_PROMPT
    try:
        result = openai_client.images.generate(
            prompt=prompt,
            size="512x512",  # —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            quality="high",
        )
        b64 = None
        if result.data and len(result.data) > 0:
            b64 = result.data[0].b64_json
        if not b64:
            raise ValueError("Empty b64 data from API")

        raw = base64.b64decode(b64)
        if not raw or len(raw) < 10240:
            raise ValueError(f"Image too small: {len(raw)} bytes")

        normalized = _normalize_image(raw)
        if normalized:
            return normalized
        return raw
    except Exception as exc:  # noqa: BLE001
        print(f"[POSTGEN] –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {exc}")
        try:
            with FALLBACK_IMAGE.open("rb") as f:
                fb = f.read()
            return _normalize_image(fb) or fb
        except Exception as e2:  # noqa: BLE001
            print(f"[POSTGEN] Fallback —Ç–æ–∂–µ –Ω–µ —É–¥–∞–ª—Å—è: {e2}")
            return None


def _publish_post(message, caption: str, image_bytes: Optional[bytes]) -> None:
    kb = types.InlineKeyboardMarkup()
    kb.add(types.InlineKeyboardButton("–ü–µ—Ä–µ–π—Ç–∏ –∫ –±–æ—Ç—É", url=BOT_LINK))

    targets = [CHANNEL_ID, GROUP_ID]

    # –µ—Å–ª–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–µ—Ç ‚Äî —Å—Ç–∞–≤–∏–º –≤–∞—à –±–∞–Ω–Ω–µ—Ä
    if not image_bytes:
        image_bytes = _read_banner_bytes()

    for target in targets:
        if image_bytes:
            try:
                buf = BytesIO(image_bytes)
                buf.name = "syntera_post.jpg"
                buf.seek(0)
                bot.send_photo(target, buf, caption=caption, parse_mode="HTML", reply_markup=kb)
            except Exception as e:
                print(f"[POSTGEN] send_photo failed: {e}")
                bot.send_message(target, caption, parse_mode="HTML", reply_markup=kb)
        else:
            bot.send_message(target, caption, parse_mode="HTML", reply_markup=kb)

    with suppress(Exception):
        bot.reply_to(message, "‚úÖ –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")


def _handle_post_request(message, mode: str) -> None:
    user_id = getattr(message.from_user, "id", None)
    if user_id != OWNER_ID:
        bot.reply_to(message, "‚õî –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª—å—Ü—É.")
        return

    status_msg = bot.reply_to(message, "üß† –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∫–æ–Ω—Ç–µ–Ω—Ç, —ç—Ç–æ –∑–∞–π–º—ë—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥‚Ä¶")

    try:
        text, image_prompt = _generate_post_payload(mode)
        image_bytes = _generate_image_bytes(image_prompt)
        _publish_post(message, text, image_bytes)
    except Exception as exc:  # noqa: BLE001
        bot.reply_to(message, f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–æ—Å—Ç: {exc}")
        traceback.print_exc()
    finally:
        with suppress(Exception):
            bot.delete_message(status_msg.chat.id, status_msg.message_id)


@bot.message_handler(commands=["post_short"])
def create_short_post(message):
    _handle_post_request(message, "short")


@bot.message_handler(commands=["post_long"])
def create_long_post(message):
    _handle_post_request(message, "long")


@bot.message_handler(commands=["post_news"])
def cmd_post_news(message):
    user_id = getattr(message.from_user, "id", None)
    if user_id != OWNER_ID:
        bot.reply_to(message, "‚õî –ö–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª—å—Ü—É.")
        return

    headline, post_text, news_url = _generate_news_payload()

    caption = (
        f"<b>{headline}</b>\n\n"
        f"{post_text}\n\n"
        f"üîó –ò—Å—Ç–æ—á–Ω–∏–∫: <a href='{news_url}'>{news_url}</a>\n\n"
        f"–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è –Ω–∞ AI Systems –∏ —É—á–∞—Å—Ç–≤—É–π –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏—è—Ö Hubconsult!"
    )

    # –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à –±–∞–Ω–Ω–µ—Ä –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π
    image_bytes = _read_banner_bytes()
    _publish_post(message, caption, image_bytes)


__all__ = [
    "create_short_post",
    "create_long_post",
    "cmd_post_news",
]
